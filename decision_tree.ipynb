{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen.models import Models\n",
    "from data_gen.models_dict_v2 import model_dict\n",
    "from data_gen.generate_synthetic_df import generate_synthetic_df\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = np.random.seed(1)\n",
    "number_of_samples = 5000\n",
    "train_ratio, valiation_ratio, test_ratio = 0.6,0.2,0.2 #i.e. 0.6*number_of_samples for training, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(sample_number, seed):\n",
    "    # Create synthetic dataframe\n",
    "    df = generate_synthetic_df(sample_number, seed)\n",
    "\n",
    "    # Instantiate an object from the class \"Models\"\n",
    "    models = Models(model_dict)\n",
    "\n",
    "    # Calculate the cost and price\n",
    "    cost = models.calculate_cost(df)\n",
    "    pricing = models.calculate_pricing(df)\n",
    "\n",
    "    # Calculate the profit on the synthetic dataframe\n",
    "    df[\"profit\"] = models.calculate_profit(cost, pricing)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_data(number_of_samples, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_one_column(column):\n",
    "    mean = np.mean(column)\n",
    "    standard_deviation = np.std(column)\n",
    "    return (column - mean)/standard_deviation\n",
    "\n",
    "def standardize(dataframe):\n",
    "    #Given a pandas dataframe, we standardize every column.\n",
    "    number_of_columns = len(dataframe.columns)\n",
    "    for j in range(number_of_columns):\n",
    "        dataframe.iloc[:,j] = standardize_one_column(dataframe.iloc[:,j])\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_X_Y(df):\n",
    "    X = df.loc[:, df.columns != 'profit']\n",
    "    Y = df[\"profit\"]\n",
    "\n",
    "    X.loc[X[\"MARITAL_STATUS\"]==\"Single\", \"MARITAL_STATUS\"] = 0\n",
    "    X.loc[X[\"MARITAL_STATUS\"]==\"Not_Single\", \"MARITAL_STATUS\"] = 0\n",
    "\n",
    "    X = X.astype(int)\n",
    "    Y = Y.astype(int)\n",
    "\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = obtain_X_Y(df)\n",
    "\n",
    "X_TRAIN = X.iloc[:int(train_ratio*number_of_samples),:]\n",
    "Y_TRAIN = Y.iloc[:int(train_ratio*number_of_samples)]\n",
    "X_VALIDATION = X.iloc[int(train_ratio*number_of_samples):int((train_ratio+valiation_ratio)*number_of_samples),:]\n",
    "Y_VALIDATION = Y.iloc[int(train_ratio*number_of_samples):int((train_ratio+valiation_ratio)*number_of_samples)]\n",
    "X_TEST = X.iloc[int((train_ratio+valiation_ratio)*number_of_samples):,:]\n",
    "Y_TEST = Y.iloc[int((train_ratio+valiation_ratio)*number_of_samples):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, y_hat):\n",
    "    return np.sum( np.square(y-y_hat) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "609317.4734580594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "min_error = 999999999999999999999\n",
    "best_depth = None\n",
    "best_regressor = None\n",
    "\n",
    "for k in range(1,15):\n",
    "    regressor = DecisionTreeRegressor(criterion=\"squared_error\", max_depth=k)\n",
    "    regressor = regressor.fit(X_TRAIN, Y_TRAIN)\n",
    "    Y_VALIDATION_HAT = regressor.predict(X_VALIDATION)\n",
    "    error = MSE(Y_VALIDATION, Y_VALIDATION_HAT)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_depth = k\n",
    "        best_regressor = regressor\n",
    "\n",
    "print(k)\n",
    "print(min_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678004.7402901736\n"
     ]
    }
   ],
   "source": [
    "Y_TEST_HAT = best_regressor.predict(X_TEST)\n",
    "error = MSE(Y_TEST_HAT, Y_TEST)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the Transition Matrix\n",
    "\n",
    "By a **state**, we mean a leaf in the best regressor trained above.\n",
    "Our first goal is to get a list of all the states and get the decision path (i.e. given X, what leaf does X fall into?).\n",
    "\n",
    "It turns out that sklearn has one id associated to each tree node. Our `state` will thus be a list of integers corresponding to these leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False  True  True False  True\n",
      "  True False False  True  True False  True  True False False False  True\n",
      "  True False  True  True False False  True  True False  True  True False\n",
      " False False False  True  True False  True  True False False  True  True\n",
      " False  True  True False False False  True  True  True False False  True\n",
      "  True False  True  True False False False False False  True  True False\n",
      "  True  True False False  True  True False  True  True False False False\n",
      "  True  True False  True  True False False  True  True False  True  True\n",
      " False False False False  True  True False  True  True False False  True\n",
      "  True False  True  True False False False  True  True False  True  True\n",
      " False False  True  True False  True  True False False False False False\n",
      " False  True  True False  True  True False False  True  True False  True\n",
      "  True False False False  True  True  True False False  True  True False\n",
      "  True  True False False False False  True  True False  True  True False\n",
      " False  True  True False  True  True False False False  True  True False\n",
      "  True  True False False  True  True False  True  True False False False\n",
      " False False  True  True False  True  True False False  True  True False\n",
      "  True  True False False False  True  True False  True  True False False\n",
      "  True  True False  True  True False False  True False  True  True False\n",
      " False False  True  True  True False False  True  True False  True  True\n",
      " False False False False False False False  True  True False  True  True\n",
      " False False  True  True False  True  True False False False  True  True\n",
      " False  True  True False False  True  True False  True  True False False\n",
      " False False  True  True False  True  True False False  True  True False\n",
      "  True  True False False False  True  True False  True  True False False\n",
      "  True  True False  True  True False False False False False  True  True\n",
      " False  True  True False False  True  True False  True  True False False\n",
      " False  True  True False  True  True False False  True  True False  True\n",
      "  True False False False False  True  True False  True  True False False\n",
      "  True  True False  True  True False False False  True  True False  True\n",
      "  True False False  True  True  True False False False False False False\n",
      "  True  True False  True  True False False  True  True False  True  True\n",
      " False False False  True  True False  True  True False False  True  True\n",
      " False  True  True False False False False  True  True False  True  True\n",
      " False False  True  True False  True  True False False False  True  True\n",
      " False  True  True False False  True  True False  True  True False False\n",
      " False False False  True  True False  True  True False False  True  True\n",
      " False  True  True False False False  True  True False  True  True False\n",
      "  True  True False  True  True]\n",
      "[  8   9  11  12  15  16  18  19  23  24  26  27  30  31  33  34  39  40\n",
      "  42  43  46  47  49  50  54  55  56  59  60  62  63  69  70  72  73  76\n",
      "  77  79  80  84  85  87  88  91  92  94  95 100 101 103 104 107 108 110\n",
      " 111 115 116 118 119 122 123 125 126 133 134 136 137 140 141 143 144 148\n",
      " 149 150 153 154 156 157 162 163 165 166 169 170 172 173 177 178 180 181\n",
      " 184 185 187 188 194 195 197 198 201 202 204 205 209 210 212 213 216 217\n",
      " 219 220 223 225 226 230 231 232 235 236 238 239 247 248 250 251 254 255\n",
      " 257 258 262 263 265 266 269 270 272 273 278 279 281 282 285 286 288 289\n",
      " 293 294 296 297 300 301 303 304 310 311 313 314 317 318 320 321 325 326\n",
      " 328 329 332 333 335 336 341 342 344 345 348 349 351 352 356 357 359 360\n",
      " 363 364 365 372 373 375 376 379 380 382 383 387 388 390 391 394 395 397\n",
      " 398 403 404 406 407 410 411 413 414 418 419 421 422 425 426 428 429 435\n",
      " 436 438 439 442 443 445 446 450 451 453 454 456 457 459 460]\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "def get_state(regressor):\n",
    "    #Source: https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "    #This method takes our regressor as input and returns an array of boolean plus an array of integers.\n",
    "    #The array of booleans will have the length same as the total number of nodes and will indicate if each is a leaf.\n",
    "    #The array of integers will have the same length as the total number of leaves and will correspond to the location of \"True\" in the boolean array.\n",
    "    \n",
    "    regressor_tree = regressor.tree_\n",
    "\n",
    "    n_nodes = regressor_tree.node_count\n",
    "    children_left = regressor_tree.children_left\n",
    "    children_right = regressor_tree.children_right\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    \n",
    "    print(is_leaves)\n",
    "    return is_leaves, np.nonzero(is_leaves)[0]\n",
    "\n",
    "is_leaves, states = get_state(best_regressor)\n",
    "print(states)\n",
    "print(len(states))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us print, say, the decision path for `X_TEST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208, 107,  78,  68, 160, 124, 105, 185,   9,  17,  24, 103, 185,\n",
       "        66, 152,  24, 225, 110,  31,  83, 102,  82, 188, 207, 223, 162,\n",
       "        70, 136,   5, 223,   4, 187,  63, 123, 199,  65,  22,   1, 154,\n",
       "        94,   9,  27,  12, 144,  98, 106, 113, 184,  14, 156, 150, 178,\n",
       "        69, 207,  35, 154, 194, 136,  83,   4, 211,  70, 162,  98,  36,\n",
       "       157, 156,  68, 156, 123,  95, 180,   1,  49,  79,  65,  63, 108,\n",
       "       152,  12, 158, 144, 144,  64,   9, 217,  22,  65,  83, 183, 200,\n",
       "       154,  38,  65,  86,  70,  95,  67, 156, 148,   9, 127, 180,  13,\n",
       "         6,  16,  65, 168, 100, 159, 124,  63,  67,  94, 187,  83, 130,\n",
       "        63, 154,  82, 126, 180, 162,   1,  15,  94,  38,  81,  67,  65,\n",
       "       106, 107, 189, 144, 139,  76,  65, 107,  98, 161,   1,  24,  94,\n",
       "        80, 127, 171,  82, 157, 154,  38, 200,  96, 177, 103, 124, 120,\n",
       "       185, 126,  15, 105,  50,  24,  49,  95, 103, 153,  63,  68, 185,\n",
       "        67,   1,  65,  70,  63, 212, 223,  63, 223,  38, 124,  94, 102,\n",
       "        67, 107, 210, 137, 156,  99,  36,   8, 223, 156,   9, 180, 168,\n",
       "       125,   4,  15,  67, 139,  98, 150, 136,  98, 169, 113,   1, 154,\n",
       "       190, 183,  86,  83, 126,  98, 212, 120,   9, 106, 127,  86, 175,\n",
       "        83,  38,  98,  87, 156,   7, 225, 176, 102,  67, 102, 102,  72,\n",
       "         8,  67,   1,   4, 189,  24, 225, 156, 102, 154, 163,  49,  98,\n",
       "       136, 183, 217,  67, 120, 136,  15, 107, 108,  79,   9,  79, 102,\n",
       "        45, 183, 150, 187,   8, 114,  13,  79,  80,  38, 105,  24, 103,\n",
       "         9, 185,  24,  94,  95, 157,  45,  49,  19, 144,  24, 186,  65,\n",
       "       177,  70,  67,  12, 194,  67, 124,  38,  12, 162, 185,  79, 154,\n",
       "       124, 103,  98, 142,  95, 156, 190, 227, 120,  38,  98, 216,  15,\n",
       "        84,  24,  38, 162,  98, 183, 104,  67, 127, 107,   6,  82,  98,\n",
       "       154,  57, 169, 142, 158,   9, 124, 120, 124, 154, 189,   1, 102,\n",
       "       154, 137, 124, 202,  61, 188,  71, 225, 136, 102,  68, 199,  24,\n",
       "       154, 146, 100, 136,  47,  64, 156,  98, 124,  97, 142, 216,   8,\n",
       "        36, 159, 162, 137,  66,  70,  63,  71, 225, 113,  49,  81,  92,\n",
       "        35,  81, 128,  38, 120,   1, 164, 216,  13,  13,  24, 154, 137,\n",
       "       117,  10,  36, 106, 157, 199, 183,  14,  63, 102,  96, 102, 183,\n",
       "       169,  63, 212, 187,  83,  66, 159, 154, 174,  67,  27,   6, 154,\n",
       "        66, 207,  79, 219, 195, 103, 113, 142,  57, 105, 149, 123,  68,\n",
       "        38,  65,  38, 102, 133,   9, 105, 145, 102, 103,  94,  79, 189,\n",
       "       106,   1, 105,  83, 120, 162,  94, 100, 212, 217, 133,  31, 107,\n",
       "       105, 173, 107, 156,  52,  23, 126, 184, 225,  82, 125, 157, 200,\n",
       "         5,  24,  66, 138,  83, 103, 102, 183, 156, 168, 152, 159, 159,\n",
       "        35,  95,  76, 190, 218, 104, 136, 142, 178, 217,  36,   4, 103,\n",
       "        14,  98,  38,  15, 207,  98,  80, 198,   8,  79,  43,  83, 159,\n",
       "        70, 225, 159, 187, 103,  83,  82,  63, 157,  94, 103, 201, 176,\n",
       "        94, 170, 158,  78, 216,  24,  36,  67, 131, 124, 156, 169,  38,\n",
       "       127,  83, 216, 200, 178, 124, 120, 128,  28, 180, 187, 154,  82,\n",
       "       168, 138,  87,  68,  24, 139, 149, 107, 225, 154, 106, 176, 127,\n",
       "        24, 152, 114,  35,  27,  24,  74, 225, 117,  50,  38, 113, 144,\n",
       "       136, 185,   6,   8,  67, 183,  36,  98, 103, 125, 176, 187,  38,\n",
       "       147, 127,  92, 100, 142,  52, 217, 162,  36,  82, 107,  50, 150,\n",
       "       217, 114,  16, 187, 103,   1,  69, 102,  66, 158,  83,  65,  47,\n",
       "        67, 103,  63,   1, 102,  36, 198, 105,   1, 178,  83, 223,  50,\n",
       "       217,  65,   1, 138, 124,  72,   9, 106, 169, 212,  70,  79,   3,\n",
       "        97, 169, 185,  12, 178,   6,  46, 102, 103,  94,  94,  97, 142,\n",
       "       177,  63,  92, 154, 105, 162,  12,  67,  47, 124,  96,  74, 186,\n",
       "        39, 185, 114,  83, 154, 188, 107,  87, 199, 176, 120, 185,   6,\n",
       "        28, 103,  65,  97, 167,   4, 217,   0,  38,  82, 100,  92, 113,\n",
       "        24,  13, 212, 228, 159,  36,   1, 102,  92,  29, 186, 154, 223,\n",
       "        92, 200,  24, 156,  14, 223,  79, 103, 147,  95, 199,  49,  95,\n",
       "       217, 105,  74, 181, 159,  67,  51, 183, 186,  83, 108, 138, 120,\n",
       "       212,   1, 188, 217, 159,  70, 185,  15, 100, 103, 124, 171, 217,\n",
       "        79, 187,  94,   1,  65, 124, 142, 102,  50,  67, 103, 169, 173,\n",
       "       161, 159, 106,  83,  49,  67, 156, 217,  92,  63,  81, 103, 124,\n",
       "       133, 103,  87, 136, 188,  70, 136, 107, 106, 185, 152,  96, 169,\n",
       "        94,  70, 144,  66, 107, 136, 183, 114,  79,  63,  98, 187, 136,\n",
       "       179, 168,  12,  83, 217,  67,  66,  93,  78, 102,  78, 185,   6,\n",
       "        33, 139, 176,  70,  93,  69,  65,  94, 141,  65,  65, 120, 223,\n",
       "       126,  13,  65, 102, 168, 185,  65,  72, 101, 102,  78, 152,  96,\n",
       "        78, 225, 176, 183,  36,  65, 181, 225,   6,  94,  96, 105,  72,\n",
       "       156,  36, 122, 146, 185,  13,  63,  98,  15, 157, 170,  70, 136,\n",
       "        39,  15, 214,  83, 177, 142, 156, 102, 113, 183,  38,  79, 124,\n",
       "        98, 136, 128,   9, 186,  74,  64,  98,  98,  98, 104, 226, 161,\n",
       "       113,  70, 126,  86, 154, 136,  67, 179, 216,  64,  94, 211, 147,\n",
       "        28,   9, 162,  94, 142, 100, 161, 176,  65, 138, 141, 154, 158,\n",
       "        94,  70,  38, 183,  68,   9,  79, 152,  31, 177,  93, 114, 187,\n",
       "       131,  79, 141, 179, 156, 128, 100, 137, 199, 103, 223, 128,  80,\n",
       "       103, 169, 136,   8, 142, 141, 136, 128,  24,  15, 162,  72,  82,\n",
       "       103,  66, 106, 210, 120,  24, 157, 121, 188, 200, 125,  72, 102,\n",
       "        12, 154, 124,  98, 154,  63, 105,   9, 212, 201, 103,  24, 167,\n",
       "       225, 161, 107, 146, 131, 124, 185,  15,   4,  18,  99,  94, 156,\n",
       "        40,  83, 162, 124,  67,  83, 141,  61,  45, 107, 154,  93],\n",
       "      dtype=uint16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_state_of_one_year(x, regressor, states):\n",
    "    x_leaf_id = regressor.apply(x)\n",
    "    x_states = np.empty(len(x), dtype = np.uint16)\n",
    "    for k in range(len(x)):\n",
    "        x_states[k] = np.where(states == x_leaf_id[k])[0][0]\n",
    "    return x_states\n",
    "\n",
    "get_state_of_one_year(X_TEST, best_regressor, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is random, we will use different seeds to generate $k$ pieces of data of same amound of clients. We assume that such is how one client changes over $k$ years. We shall focus on the mechanism of getting the transition probabilities and will ignore the fact that the client does not age by exactly one year old in the next year.\n",
    "\n",
    "We remark that, in order for the calculation to work, we must have at least one client for every state. This might not hold. Therefore, we use a large group of clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168  95 120 ...   0  64 173]\n"
     ]
    }
   ],
   "source": [
    "k = 50 #number of years\n",
    "seeds = np.random.choice(1000, k)\n",
    "#yearly_X = []\n",
    "yearly_state = []\n",
    "sample_number = 5000\n",
    "\n",
    "for i in range(k):\n",
    "    new_dataframe = generate_data(sample_number, seeds[i])\n",
    "    x,_ = obtain_X_Y(new_dataframe)\n",
    "    #yearly_X.append(x)\n",
    "    yearly_state.append(get_state_of_one_year(x,best_regressor, states))\n",
    "\n",
    "print(yearly_state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00286944 0.0143472  0.         ... 0.         0.00143472 0.        ]\n",
      " [0.00319795 0.01183243 0.0003198  ... 0.0003198  0.0003198  0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def compute_transition_matrix(yearly_state, number_of_states):\n",
    "    number_of_years = len(yearly_state)\n",
    "    number_of_clients = len(yearly_state[0])\n",
    "    transition_matrix = np.zeros((number_of_states,number_of_states), dtype = np.uint16)\n",
    "\n",
    "\n",
    "    #For each time t, we count the number of clients starting at state l and end at every state.\n",
    "    #Once this is done, we make each row a probability vector.\n",
    "\n",
    "    for t in range(number_of_years-1):\n",
    "        for n in range(number_of_clients):\n",
    "            state_this_year = int(yearly_state[t][n])\n",
    "            state_next_year = int(yearly_state[t+1][n])\n",
    "            transition_matrix[state_this_year,state_next_year] += 1\n",
    "    \n",
    "    transition_matrix = transition_matrix.astype(np.float64)\n",
    "    for l in range(number_of_states):\n",
    "        row_sum = np.sum(transition_matrix[l])\n",
    "        transition_matrix[l] = transition_matrix[l]/row_sum\n",
    "    \n",
    "    return transition_matrix\n",
    "\n",
    "transition_matrix = compute_transition_matrix(yearly_state, len(states))\n",
    "print(transition_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
