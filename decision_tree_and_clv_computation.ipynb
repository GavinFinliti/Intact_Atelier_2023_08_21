{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen.models import Models\n",
    "from data_gen.models_dict_v2 import model_dict\n",
    "from data_gen.generate_synthetic_df import generate_synthetic_df\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = np.random.seed(1)\n",
    "number_of_samples = 5000\n",
    "train_ratio, valiation_ratio, test_ratio = 0.6,0.2,0.2 #i.e. 0.6*number_of_samples for training, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(sample_number, seed):\n",
    "    # Create synthetic dataframe\n",
    "    df = generate_synthetic_df(sample_number, seed)\n",
    "\n",
    "    # Instantiate an object from the class \"Models\"\n",
    "    models = Models(model_dict)\n",
    "\n",
    "    # Calculate the cost and price\n",
    "    cost = models.calculate_cost(df)\n",
    "    pricing = models.calculate_pricing(df)\n",
    "\n",
    "    # Calculate the profit on the synthetic dataframe\n",
    "    df[\"profit\"] = models.calculate_profit(cost, pricing)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_data(number_of_samples, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_one_column(column):\n",
    "    mean = np.mean(column)\n",
    "    standard_deviation = np.std(column)\n",
    "    return (column - mean)/standard_deviation\n",
    "\n",
    "def standardize(dataframe):\n",
    "    #Given a pandas dataframe, we standardize every column.\n",
    "    number_of_columns = len(dataframe.columns)\n",
    "    for j in range(number_of_columns):\n",
    "        dataframe.iloc[:,j] = standardize_one_column(dataframe.iloc[:,j])\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_X_Y(df):\n",
    "    X = df.loc[:, df.columns != 'profit']\n",
    "    Y = df[\"profit\"]\n",
    "\n",
    "    X.loc[X[\"MARITAL_STATUS\"]==\"Single\", \"MARITAL_STATUS\"] = 0\n",
    "    X.loc[X[\"MARITAL_STATUS\"]==\"Not_Single\", \"MARITAL_STATUS\"] = 0\n",
    "\n",
    "    X = X.astype(int)\n",
    "    Y = Y.astype(int)\n",
    "\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = obtain_X_Y(df)\n",
    "\n",
    "X_TRAIN = X.iloc[:int(train_ratio*number_of_samples),:]\n",
    "Y_TRAIN = Y.iloc[:int(train_ratio*number_of_samples)]\n",
    "X_VALIDATION = X.iloc[int(train_ratio*number_of_samples):int((train_ratio+valiation_ratio)*number_of_samples),:]\n",
    "Y_VALIDATION = Y.iloc[int(train_ratio*number_of_samples):int((train_ratio+valiation_ratio)*number_of_samples)]\n",
    "X_TEST = X.iloc[int((train_ratio+valiation_ratio)*number_of_samples):,:]\n",
    "Y_TEST = Y.iloc[int((train_ratio+valiation_ratio)*number_of_samples):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, y_hat):\n",
    "    return np.sum( np.square(y-y_hat) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "570894.8059498647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "min_error = 999999999999999999999\n",
    "best_depth = None\n",
    "best_regressor = None\n",
    "\n",
    "for k in range(1,15):\n",
    "    regressor = DecisionTreeRegressor(criterion=\"squared_error\", max_depth=k)\n",
    "    regressor = regressor.fit(X_TRAIN, Y_TRAIN)\n",
    "    Y_VALIDATION_HAT = regressor.predict(X_VALIDATION)\n",
    "    error = MSE(Y_VALIDATION, Y_VALIDATION_HAT)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_depth = k\n",
    "        best_regressor = regressor\n",
    "\n",
    "print(k)\n",
    "print(min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626696.8027692847\n"
     ]
    }
   ],
   "source": [
    "Y_TEST_HAT = best_regressor.predict(X_TEST)\n",
    "error = MSE(Y_TEST_HAT, Y_TEST)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the Transition Matrix\n",
    "\n",
    "By a **state**, we mean a leaf in the best regressor trained above.\n",
    "Our first goal is to get a list of all the states and get the decision path (i.e. given X, what leaf does X fall into?).\n",
    "\n",
    "It turns out that sklearn has one id associated to each tree node. Our `state` will thus be a list of integers corresponding to these leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8   9  11  12  15  16  18  19  23  24  26  27  30  31  33  34  39  40\n",
      "  42  43  46  47  49  50  54  55  57  58  61  62  64  65  71  72  74  75\n",
      "  78  79  81  82  86  87  89  90  93  94  96  97 102 103 105 106 109 110\n",
      " 112 113 117 118 120 121 124 125 127 128 135 136 138 139 142 143 145 146\n",
      " 150 151 153 154 157 158 160 161 166 167 169 170 173 174 176 177 181 182\n",
      " 184 185 188 189 191 192 198 199 201 202 205 206 208 209 213 214 216 217\n",
      " 220 221 223 224 229 230 232 233 234 238 239 241 242 245 246 248 249 257\n",
      " 258 260 261 264 265 267 268 272 273 275 276 278 279 284 285 287 288 291\n",
      " 292 294 295 299 300 302 303 306 307 309 310 316 317 319 320 323 324 326\n",
      " 327 331 332 334 335 338 339 341 342 347 348 350 351 354 355 357 358 361\n",
      " 363 364 366 367 374 375 377 378 381 382 384 385 389 390 392 393 396 397\n",
      " 398 403 404 406 407 410 411 413 414 418 419 421 422 425 426 428 429 435\n",
      " 436 438 439 442 443 445 446 450 451 453 454 457 458 460 461 466 467 469\n",
      " 470 473 474 476 477 480 482 483 484]\n"
     ]
    }
   ],
   "source": [
    "def get_state(regressor):\n",
    "    \"\"\" Return the indices of the leaf nodes in the decision tree. \"\"\"\n",
    "    regressor_tree = regressor.tree_\n",
    "    return np.where(regressor_tree.children_left == regressor_tree.children_right)[0]\n",
    "\n",
    "states = get_state(best_regressor)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.29000000e+02, -1.04250000e+02, -6.99473684e+01, -9.02162162e+01,\n",
       "       -2.48000000e+02, -2.21000000e+02, -1.16500000e+02, -1.79750000e+02,\n",
       "       -7.78571429e+01, -5.61304348e+01, -8.27727273e+01, -1.27500000e+02,\n",
       "       -5.32222222e+01, -2.76470588e+01, -8.25000000e+01, -5.01290323e+01,\n",
       "       -2.31000000e+02, -1.55000000e+02, -3.02000000e+02, -3.01000000e+02,\n",
       "       -1.64368421e+02, -1.18000000e+02, -2.30000000e+02, -2.80000000e+02,\n",
       "       -1.29000000e+02, -1.58764706e+02, -2.69000000e+02, -1.52500000e+02,\n",
       "       -1.00153846e+02, -7.21250000e+01, -1.94200000e+02, -1.28600000e+02,\n",
       "       -3.70769231e+01, -1.56000000e+01, -8.26363636e+01, -5.32777778e+01,\n",
       "       -3.02727273e+01, -9.81250000e+00, -2.58235294e+01, -3.89600000e+01,\n",
       "        9.40000000e+00, -1.00000000e+01, -1.60000000e+01, -3.60000000e+01,\n",
       "        4.25000000e+00,  1.35000000e+01,  2.70000000e+01,  2.50000000e+01,\n",
       "       -7.23333333e+01, -1.02400000e+02, -3.90000000e+01, -3.00000000e+01,\n",
       "       -1.18000000e+02, -7.80000000e+01, -1.99000000e+02, -1.49500000e+02,\n",
       "       -8.90000000e+01, -1.32000000e+02, -3.60000000e+01, -6.65000000e+01,\n",
       "       -2.96250000e+01, -4.25000000e+00, -3.00000000e+01, -6.58333333e+01,\n",
       "       -5.11794872e+01, -1.00333333e+02, -1.02333333e+02, -7.30000000e+01,\n",
       "       -2.68888889e+01, -5.58095238e+01, -6.60000000e+01, -2.73793103e+01,\n",
       "       -1.51777778e+01, -2.38461538e+00, -5.35000000e+01, -2.10000000e+01,\n",
       "       -6.00000000e+01, -3.30454545e+01, -2.27959184e+01, -4.28000000e+01,\n",
       "       -7.05000000e+01, -3.70000000e+01, -1.25000000e+02, -8.35263158e+01,\n",
       "       -8.00000000e+01, -9.60000000e+01, -8.30000000e+01, -1.76000000e+02,\n",
       "       -2.45000000e+01, -4.43750000e+01, -2.60000000e+01, -6.78000000e+01,\n",
       "       -5.10000000e+01, -2.10000000e+01, -9.51666667e+01, -7.90000000e+01,\n",
       "       -1.66938776e+01, -5.28571429e+00, -5.18461538e+01, -2.10000000e+01,\n",
       "        1.57037037e+01, -2.16666667e+00, -7.19230769e+00,  4.03125000e+00,\n",
       "       -2.00000000e+01, -4.54090909e+01,  1.03333333e+01, -2.06666667e+01,\n",
       "       -5.91428571e+01, -2.82500000e+01, -1.14000000e+02, -7.76666667e+01,\n",
       "       -1.10000000e+01, -4.20000000e+01,  2.20000000e+01,  9.66666667e+00,\n",
       "       -8.10000000e+01,  2.06428571e+01,  3.29047619e+01,  1.48461538e+01,\n",
       "       -1.12000000e+01,  3.38333333e+01,  5.25000000e+01,  6.10000000e+01,\n",
       "        5.06666667e+01, -1.39000000e+01, -3.49000000e+01,  9.83333333e+00,\n",
       "       -9.07692308e+00,  1.39183673e+01, -5.88235294e-02,  3.65384615e-01,\n",
       "       -1.63000000e+01, -5.40000000e+01, -1.12500000e+01, -7.90000000e+01,\n",
       "       -3.67368421e+01, -1.13000000e+02, -9.10000000e+01,  2.75217391e+01,\n",
       "        3.66428571e+01,  2.29444444e+01,  1.08000000e+01,  4.34545455e+01,\n",
       "        5.28500000e+01,  6.80000000e+01,  7.80000000e+01,  2.40000000e+01,\n",
       "        8.25000000e+00,  1.45833333e+00, -2.03529412e+01,  8.85714286e+00,\n",
       "        3.10909091e+01,  6.90000000e+01,  5.00000000e+01,  3.49583333e+01,\n",
       "        1.72000000e+01,  3.79879518e+01,  2.45000000e+01,  4.56363636e+01,\n",
       "        5.39583333e+01,  3.14444444e+01,  4.21333333e+01,  4.64545455e+01,\n",
       "        6.14444444e+01,  3.43076923e+01,  2.40000000e+01,  5.53888889e+01,\n",
       "        6.42105263e+01,  7.48000000e+01,  6.98333333e+01, -1.70000000e+01,\n",
       "       -3.70000000e+01,  1.16666667e+01, -6.25000000e-01,  2.30000000e+01,\n",
       "       -1.00000000e+00,  2.94000000e+01,  5.20000000e+01, -1.30000000e+01,\n",
       "       -6.90000000e+01, -4.75000000e+01,  1.00000000e+01, -1.80000000e+01,\n",
       "        5.07666667e+01,  2.30000000e+01,  6.38611111e+01,  5.32777778e+01,\n",
       "        7.22500000e+01,  6.77500000e+01,  5.55714286e+01,  7.00000000e+01,\n",
       "        7.54615385e+01,  6.75185185e+01,  7.74545455e+01,  7.00000000e+01,\n",
       "        8.63333333e+01,  8.21250000e+01,  7.20000000e+01,  7.44000000e+01,\n",
       "        7.85500000e+01,  7.42000000e+01,  6.55714286e+01,  8.53181818e+01,\n",
       "        7.90000000e+01,  6.80000000e+01,  7.60000000e+01,  8.50714286e+01,\n",
       "        7.75000000e+01,  8.87200000e+01,  9.18333333e+01,  9.42777778e+01,\n",
       "        8.96666667e+01,  9.00000000e+01,  8.56666667e+01,  9.80000000e+01,\n",
       "        1.01000000e+02,  9.50000000e+01,  8.90000000e+01,  1.04238095e+02,\n",
       "        1.00200000e+02,  9.87500000e+01,  1.02500000e+02,  1.07000000e+02,\n",
       "        1.11500000e+02,  1.07000000e+02,  1.04666667e+02,  1.19000000e+02,\n",
       "        1.14125000e+02,  1.06600000e+02,  1.11750000e+02,  1.21071429e+02,\n",
       "        1.13000000e+02,  1.31357143e+02,  1.21200000e+02,  1.47900000e+02,\n",
       "        1.59142857e+02,  1.22000000e+02,  1.46500000e+02,  8.20000000e+01,\n",
       "        9.60000000e+01,  1.06500000e+02,  5.00000000e+01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_profit_list(regressor):\n",
    "    #this method returns a list such that, the profit of state i is list[i].\n",
    "    states = get_state(best_regressor)\n",
    "    value_list = regressor.tree_.value.squeeze()\n",
    "    return value_list[states]\n",
    "\n",
    "get_profit_list(best_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us print, say, the decision path for `X_TEST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  96,  15, 139, 163,   1,  73, 184, 196,  82,  73, 129, 193,\n",
       "        58, 202,  96,  36,  71, 107, 159,  59, 103, 157,  97,  97, 130,\n",
       "        97, 186, 156, 157, 129, 140,  36, 202, 162, 139,  38, 125, 213,\n",
       "       129, 159,  35, 140, 129, 157, 213, 129,  15, 215,  64,  78, 157,\n",
       "       112, 139,  80, 117, 157, 157, 162, 158,  96,  10, 167,   9,   3,\n",
       "       130,  49, 141, 111,  35,  36, 129, 129,  37, 129,   2,   2,  35,\n",
       "       150, 202,  32, 239,  97,  72, 174,  64,   2,  36, 190,   3, 186,\n",
       "        15, 152, 119,   1,   2,  39, 118, 100, 109, 177, 167,   1,   0,\n",
       "       170, 141, 160, 140,  97, 148, 215, 163,   5, 220, 159, 139, 139,\n",
       "       228, 163,  49,  35,  36, 129,  15,  75, 103, 193,   3,  96,  15,\n",
       "       157,  39, 159, 200,   3, 160, 163,  39,  99,   2, 100, 211,  37,\n",
       "        68, 140,   9,  28, 161,  25, 139,  44, 174, 156, 139,  97, 156,\n",
       "       139,  13, 140, 203,  44,  11, 160,  62, 125,  97, 159,  97, 155,\n",
       "       203,  35, 156, 154, 178, 139,  80, 130, 219,  73,  71,  72, 213,\n",
       "        12,  20,  34, 156, 167,  72,  35, 159, 163, 235,  36, 117, 128,\n",
       "       169, 168,  77, 100,   2, 140, 133,   2, 209,  71, 158,  78, 200,\n",
       "       153,  34,  10, 129,  97,  15, 184, 105,   2,  76,  32, 129, 107,\n",
       "        96,   2, 144, 233, 103,  35,  12, 157, 202, 141, 150, 100, 159,\n",
       "        35,   1,   2, 147,  78, 207, 201,  29,   6, 125, 157,   6, 159,\n",
       "        73, 189, 124,  72, 139, 157, 119, 109, 167, 157, 129,  81,  38,\n",
       "       142, 102, 184, 159, 117,   1,  80, 204,   1, 163, 173, 124, 193,\n",
       "        97, 117,  37, 159, 150, 131, 117, 157, 186, 140, 131,  28,  99,\n",
       "       129, 233, 202, 192, 103,   2, 100, 186, 100,  97, 156,   3, 234,\n",
       "       131,   1, 147, 141, 213,  78,  81, 118, 129,   2, 131, 140, 126,\n",
       "       130, 167, 175,  83, 103, 158,  72, 102, 228,  10,  37,   2,  96,\n",
       "       157, 166, 167, 167, 140, 100,  58, 100,   9,   2,   3, 193,  73,\n",
       "       129, 169,  36, 230, 139, 129,  91,   1, 167,  59, 149, 157, 141,\n",
       "       107, 157, 213, 109,  97, 139, 125, 122, 157, 119,  29, 107, 168,\n",
       "       139,  49,  98, 130, 175, 104, 140,  72,  97, 134, 209, 189,  38,\n",
       "       131, 139, 141, 131, 152, 147, 228, 133, 158,  72, 101, 144,  97,\n",
       "         3,  83,  35,   3,   3, 219, 163, 134,  90, 103,  71, 201,  50,\n",
       "       159,  80, 128, 132, 104, 161,  16,  96, 100, 186, 209, 241,   3,\n",
       "       169,  78,  37, 207,  12, 192,   3,  36, 129,  80, 100,  97, 156,\n",
       "       100,  39, 131, 117,  71, 193,  41,  39, 175, 167, 219,  44,  91,\n",
       "        29, 122,   3, 231, 160, 142,  97,  72,  78, 155,  10,  58, 131,\n",
       "        97,  15, 228, 139, 158, 103, 160, 160, 118, 142, 184, 140, 155,\n",
       "        29, 157, 163,  57, 129, 156, 152, 231, 151,  78,   9,  15, 102,\n",
       "       213, 124,  51, 102, 170,  72,  15, 211, 104, 130, 221, 200,   5,\n",
       "        35, 159, 117, 103, 105,  58, 143, 159, 168, 131,  39, 134, 189,\n",
       "       156, 159,  12, 167, 182, 141, 156, 157, 196,  97, 157,  80, 124,\n",
       "       184,  97, 211,  12,  99, 203, 231, 141,   3, 209, 103, 173, 154,\n",
       "       148, 159,  53, 175,   9,  78,  78,  25, 126, 233, 163, 159, 202,\n",
       "         3, 211, 194, 167, 103, 219, 199,  39,  84,  81, 151, 139, 121,\n",
       "       125, 167, 192, 184, 216,  97, 160, 149, 101, 161, 139, 129,   1,\n",
       "         2,  28, 188, 149, 156, 102,  22,  98, 105, 100, 108, 175, 140,\n",
       "       131,   2, 129,  15, 192, 103, 211,  76, 139, 184, 151, 188, 127,\n",
       "       139, 221,  96, 100, 156, 118, 187, 145, 100, 111,  78, 139, 209,\n",
       "        69,  21, 200,  72,   1, 160, 131,  25, 130,  97, 159,   0, 159,\n",
       "       160, 219, 125,  52,  96, 139,  35, 212,  20, 141, 219,  14, 231,\n",
       "       184,  96, 211, 164, 188,  73, 103, 148, 102, 125, 132,  28,  15,\n",
       "       129,   3,  72, 211,  58,  13,  37, 168, 117,  97, 156, 108,  10,\n",
       "       132, 208,   2, 102, 139,  78,  88,  71,   3, 157, 104, 127, 103,\n",
       "        56, 194, 163, 115, 150,  45, 186,  79, 150, 125, 126, 186, 129,\n",
       "       125, 119, 125, 207, 163,  38,  78,  68, 130, 156,  72,  97, 131,\n",
       "       107,  99, 167, 214,   2, 125, 139, 139,  71, 103, 157,  72, 175,\n",
       "        20, 210, 159, 149, 129, 157, 129,  18,  57, 200, 153,  32,  80,\n",
       "       190, 129, 107, 159,  64, 139,  99, 149,  73, 156, 129, 193,  96,\n",
       "         2, 186, 155, 131, 139, 156, 200, 157, 164,  55, 139, 129, 178,\n",
       "       129,  38, 203,   3, 153, 139,  21, 106, 147,  15, 136,  64, 131,\n",
       "       236,  72,  78, 134, 140, 235, 139, 103, 197, 207, 205,  21,  39,\n",
       "        72,  97,  75,  35,  29,   9, 193,  15,   9,  98, 128,  72, 232,\n",
       "        15,  35, 105, 102,  13, 129, 129, 159,  97, 129,  78,   1,  31,\n",
       "       201, 100, 200, 223,   3,  37, 157, 129, 129,  68, 107, 193, 173,\n",
       "        29,   1,  99, 147, 200,  47, 235, 130, 233,   0, 201,  35, 163,\n",
       "        80, 186, 163, 177,   1,  99, 219,  72,   3,  41, 103,  75,   3,\n",
       "        42,   2, 117, 139,  28, 132,  78, 169, 159, 103,  80, 175, 103,\n",
       "       139, 186, 139, 100, 193, 160,  96,  45, 225, 159,  12,  16, 163,\n",
       "         5, 156, 103, 186, 157, 118, 211,   1,  97, 188,   3, 189,   1,\n",
       "       209, 131, 150,  72, 236, 156,  72, 100,  20, 211,  37, 159,  71,\n",
       "       241, 160,  32, 211,  54,  72, 188, 163, 184,  80, 141,  72,  77,\n",
       "       148,  97, 158,  83,  32, 188, 131,  83, 159, 191, 224, 103, 167,\n",
       "       129, 194, 131, 104, 157, 125,  79,  71, 156, 193, 167,  13, 188,\n",
       "        15, 130,  39,  88,  69, 103, 187, 175,   2,  14, 157,  69, 159,\n",
       "       105, 186,  40, 100,  31,  24, 157, 129, 140, 102,  34,  24, 176,\n",
       "       139, 125,  75, 156,  72,   3, 129,  69,  98, 125, 163, 131,  29,\n",
       "        72, 160,  78, 190,  97,  14, 197, 129, 221,  96,  15, 109,  12,\n",
       "       129, 219, 131, 187, 184, 190, 129,  57, 108,  78, 156,  15],\n",
       "      dtype=uint16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_state_of_one_year(x, regressor, states):\n",
    "    x_leaf_id = regressor.apply(x)\n",
    "    x_states = np.empty(len(x), dtype = np.uint16)\n",
    "    for k in range(len(x)):\n",
    "        x_states[k] = np.where(states == x_leaf_id[k])[0][0]\n",
    "    return x_states\n",
    "\n",
    "get_state_of_one_year(X_TEST, best_regressor, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is random, we will use different seeds to generate $k$ pieces of data of same amound of clients. We assume that such is how one client changes over $k$ years. We shall focus on the mechanism of getting the transition probabilities and will ignore the fact that the client does not age by exactly one year old in the next year.\n",
    "\n",
    "We remark that, in order for the calculation to work, we must have at least one client for every state. This might not hold. Therefore, we use a large group of clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167 209 186 ...  99 141  97]\n"
     ]
    }
   ],
   "source": [
    "k = 50 #number of years\n",
    "seeds = np.random.choice(1000, k)\n",
    "#yearly_X = []\n",
    "yearly_state = []\n",
    "sample_number = 5000\n",
    "\n",
    "for i in range(k):\n",
    "    new_dataframe = generate_data(sample_number, seeds[i])\n",
    "    x,_ = obtain_X_Y(new_dataframe)\n",
    "    #yearly_X.append(x)\n",
    "    yearly_state.append(get_state_of_one_year(x,best_regressor, states))\n",
    "\n",
    "print(yearly_state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00895522 0.02686567 ... 0.         0.         0.        ]\n",
      " [0.00152497 0.00991231 0.0186809  ... 0.         0.00038124 0.        ]\n",
      " [0.00131027 0.01048218 0.01677149 ... 0.         0.00052411 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00714286 0.00714286 ... 0.         0.         0.        ]\n",
      " [0.         0.06976744 0.02325581 ... 0.         0.02325581 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def compute_transition_matrix(yearly_state, number_of_states):\n",
    "    number_of_years = len(yearly_state)\n",
    "    number_of_clients = len(yearly_state[0])\n",
    "    transition_matrix = np.zeros((number_of_states,number_of_states), dtype = np.uint16)\n",
    "\n",
    "    #For each time t, we count the number of clients starting at state l and end at every state.\n",
    "    #Once this is done, we make each row a probability vector.\n",
    "\n",
    "    for t in range(number_of_years-1):\n",
    "        for n in range(number_of_clients):\n",
    "            state_this_year = int(yearly_state[t][n])\n",
    "            state_next_year = int(yearly_state[t+1][n])\n",
    "            transition_matrix[state_this_year,state_next_year] += 1\n",
    "    \n",
    "    transition_matrix = transition_matrix.astype(np.float64)\n",
    "    for l in range(number_of_states):\n",
    "        row_sum = np.sum(transition_matrix[l])\n",
    "        if row_sum == 0:\n",
    "            transition_matrix[l] = (1/number_of_states)*np.ones(len(transition_matrix[l]))\n",
    "        else:\n",
    "            transition_matrix[l] = transition_matrix[l]/row_sum\n",
    "    \n",
    "    return transition_matrix\n",
    "\n",
    "transition_matrix = compute_transition_matrix(yearly_state, len(states))\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Computation of Customer Lifetime Value(CLV)\n",
    "\n",
    "Fix a client of Intact.\n",
    "We are now in a position of defining the concept of customer lifetime value and introduce our algorithm to compute it.\n",
    "\n",
    "Let $A$ with some $\\sigma$-algebra be a measurable space, called the **state space**. For each $t \\in \\{0,1,2,\\cdots\\}$, the **client state** is an $A$-valued random variable $S_t$, all defined on one common probability space $(\\Omega, F, P)$. For fixed bounded measurable **profit function** $f: A \\to \\mathbb{R}$ and a **discounting factor** $\\gamma = \\frac{1}{1.15}$, we define, for every non-negative integer $t_0$ and every $a \\in A$:\n",
    "\n",
    "\\begin{equation*}\n",
    "CLV_{t_0}(a) = \\mathbb{E}[\\sum_{t=t_0 + 1}^{\\tau} \\gamma^t f(S_t) \\mid S_{t_0} = a]\n",
    "\\end{equation*}\n",
    "\n",
    "Here $\\tau$ is a positive finite stopping time indicating the time which client first quits using Intact. Our goal is to compute $CLV_0(a)$ for every $a \\in A$. \n",
    "\n",
    "[//]: <1. Enlarge the transition matrix with one row at bottom and one column at right. The bottom right corner of the matrix is $1$. Fill the last row with $0$ and the last column with $0.15$. Normalize the matrix so that it remains a transition matrix. The new state we have added represents the probability of client quiting Intact.>\n",
    "\n",
    "\n",
    "Let $a \\in A$ be given. For every $a' \\in A$, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "P\\{S_1=a' \\mid S_0=a\\} = P\\{S_1=a' \\mid S_0=a, \\text{client remains}\\} P\\{ \\text{client remains} \\mid S_0=a\\} \n",
    "\\end{equation*}\n",
    "\n",
    "The term $P\\{S_1=a' \\mid S_0=a, \\text{client remains}\\}$ on the right hand side is taken care of by the transition matrix computed above. We take $P\\{ \\text{client remains} \\mid S_0=a\\} = 0.15$. Generate standard uniform $V$. If $V < P\\{ \\text{client remains} \\mid S_0=a\\}$, then the client quits. Otherwise, generate independent standard uniform $U$, which looks at the transition matrix and decide the value of $S_1$. Had simulated the state of $S_t$, repeat in this manner to generate the state of $S_{t+1}$. In doing so, we have generating a sample for the integrand. We then compute the expectation using Kolmogorov's strong law of large numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_paths(number_of_paths, transition_matrix, initial_state, years_limit = 100, client_quit_rate = 0.15):\n",
    "    sample_paths = []\n",
    "    for _ in range(number_of_paths):\n",
    "        sample_paths.append(generate_one_sample_path(transition_matrix, initial_state, years_limit, client_quit_rate))\n",
    "    return sample_paths\n",
    "\n",
    "def generate_one_sample_path(transition_matrix, initial_state, years_limit = 100, client_quit_rate = 0.15):\n",
    "    number_of_states = transition_matrix.shape[0]\n",
    "    assert initial_state < number_of_states, \"State cannot be larger than dimension of matrix.\"\n",
    "    sample_path = [initial_state]\n",
    "    while True:\n",
    "        v = np.random.uniform(low=0.0, high=1.0, size=1)[0]\n",
    "        if v < client_quit_rate:\n",
    "            sample_path.append(-1)\n",
    "            return sample_path\n",
    "        last_state = sample_path[-1]\n",
    "        next_state = np.random.choice([i for i in range(number_of_states)], p=transition_matrix[last_state])\n",
    "        sample_path.append(next_state)\n",
    "        if len(sample_path) > years_limit:\n",
    "            return sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLV_one_path(path, profit_list, initial_time = 0, discounting_factor = 1/1.15):\n",
    "    #Let only one sample path be given. We compute the CLV.\n",
    "    clv = 0\n",
    "    for t in range(len(path)):\n",
    "        if path[t] != -1: #i.e. the client does not quit\n",
    "            clv += discounting_factor**(initial_time + 1 + t)*profit_list[path[t]]\n",
    "    return clv\n",
    "\n",
    "def CLV_estimation(profit_list, initial_state, transition_matrix, initial_time = 0, discounting_factor = 1/1.15, number_of_paths = 10**4):\n",
    "    sample_paths = generate_sample_paths(number_of_paths, transition_matrix, initial_state, years_limit = 100, client_quit_rate = 0.15)\n",
    "    clv_samples = np.array([CLV_one_path(path, profit_list, initial_time, discounting_factor) for path in sample_paths])\n",
    "    return np.mean(clv_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-203.50669765715207, -77.15378044894227, -7.010352071103151, -91.19328063228552, -202.88298712348083, -206.8065889017592, -103.0836576550898, -160.9683468494196, -46.47859885076396, -24.591855593605068, -57.775594710112976, -100.03890380384334, -48.990025708284136, -12.535604364161658, -100.11403339659728, -7.016493745989683, -189.26918620913267, -109.38025164924052, -262.75592510871473, -261.97417774743064, -137.14757538762015, -69.80341893223341, -157.5435059382397, -284.6649921435943, -145.69462017201963, -112.28221849263643, -236.0579828281193, -155.59537460916474, -87.63872293334585, -53.46772296576118, -135.37600064023934, -81.99942686191726, -34.51250373159436, 0.5343804435717019, -50.18415586871921, -30.52701018486756, -20.67569563125925, -9.466942602310592, -16.745131108883847, -63.22835525248227, 76.57589726431415, -1.619321184245584, 11.213499566120504, -7.86284249371312, 22.976501538527863, 20.3784677566642, 23.17912116291539, 24.794581750858605, -68.19818975389032, -60.70387559205685, 10.036843275217077, -14.768161920071773, -100.04590951114878, -40.509211432624205, -152.73455578878247, -147.75629601141412, -80.4760759633812, -120.65094226508077, -30.95382519428785, -17.64566123776022, -31.8769350063484, -9.505987587784784, -38.367651157908824, -8.85557090071099, -7.835190734445966, -102.69476916882577, -121.67441037747805, -73.10187747605926, -12.149401274253373, -79.39303467188509, -43.88610405069297, -35.856619049958134, 8.765008250682925, 7.96183603029746, -44.811535362659555, -41.98655017490917, -22.903172467298184, 17.19396289020942, -14.745835683959461, -45.249710507535404, -48.575793680595766, 8.084293835655995, -83.69186026855377, -51.15981540086854, -65.10122186650432, -80.70238823404468, -60.153205511884735, -132.19094385159372, -32.952936840795694, -41.71945244497956, -6.880847488395295, -60.02213426654565, -85.11254924977558, -22.717109415828123, -78.86199961629396, -72.11614891866958, -14.131258042276121, 14.437141949350618, -48.8340632562881, -13.777708085514544, 12.319562036118546, -11.338562798275218, 0.34771960174765726, -23.4692084142482, -30.814254451872426, -36.6563896105216, -1.3671875250969812, -20.19122404644356, -32.63894799143362, -23.969788266256206, -66.23477379471102, -77.44040246061381, -53.52879888408832, -30.894093712349672, 30.471908379393206, -35.878641795869584, -81.275931747037, 3.0168095365578376, 18.92532274430683, 39.99488247126895, -20.08686022821724, 103.5136642448221, 27.38363209757236, 69.45460839669214, 58.13494756290669, -1.379386953965664, -39.426662621003985, -36.93505086370204, -26.201635581565238, -16.560414105768583, 29.798061434836473, 20.518272469483612, 8.591062251872842, -26.207867975012952, 22.655617772907455, -42.37493005606209, 8.162061771836587, -72.85182895468823, -70.0051610107337, 28.55229160852134, 48.790911565991664, 12.99414342915992, 32.902255204888796, 54.11614750976911, 69.36774263398543, 86.84158645848382, 68.49935988927226, 18.272023501228112, -0.12254748436663547, 1.1781878690855592, -4.3109016353439715, 35.974368241599954, -7.055466255929862, 76.1050112055443, 36.76092228954889, 25.792199669292096, 67.76754620003832, -4.743891553702516, 61.81277844313951, 29.698527965807955, 81.32935652064563, 21.924051964292534, 36.27026250160575, 27.69163978032561, 88.52157428920292, 46.568570815245735, -15.80663702971872, 44.09084952606854, 51.7040675070039, 96.72307385431012, 28.068878171161845, -38.25233364962939, -29.74468983644429, -15.732948657066412, -4.661339235710569, 10.621023306710942, 7.320539708905938, 41.74789360705971, 83.47681005000638, -0.4135338638510689, -33.963234674987675, -55.38034282139097, 15.165550714796577, 6.894973309222098, 68.80178953388486, -16.025353551743386, 64.13890073317891, 19.73092314504342, 62.2675028872786, 72.1280542948677, 51.339802646815734, 90.3329975933407, 43.39835124898801, 64.76957769762375, 73.81971567579754, 78.40648239498117, 67.28542261650031, 56.9714514706739, 74.07182922642791, 108.21990356594547, 92.67841838589177, 32.76461518559497, 45.34214125663866, 67.44560719603491, 90.95476459225344, 42.17577413977283, 66.33648971645421, 70.11809555066327, 92.2415313146877, 106.43066024196716, 74.40480517415317, 62.072974685619286, 112.10422657515888, 63.219745793599124, 50.137752223883126, 93.50133159878665, 142.0409514141077, 72.79910990409374, 92.32203443388522, 108.9334425241796, 106.04009645150957, 94.71433366073066, 67.72864896025325, 84.68446030293366, 86.40518084915153, 104.70276452578105, 75.39072633275576, 102.75330173259108, 126.9621658615506, 127.10993715182137, 89.03401483863134, 138.1286516512511, 107.03041480099527, 104.92853731345046, 81.72520238571246, 159.58480557612828, 151.99950012500102, 158.10171791880776, 147.19636686732304, 121.41851282232624, 71.90851138808752, 86.67001352457237, 46.65735070547483]\n"
     ]
    }
   ],
   "source": [
    "CLV_0 = []\n",
    "for i in range(len(states)):\n",
    "    CLV_0.append(CLV_estimation(profit_list = get_profit_list(best_regressor), initial_state= i,\n",
    "transition_matrix = transition_matrix, initial_time= 0, discounting_factor = 1/1.15, number_of_paths = 10))\n",
    "\n",
    "print(CLV_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
